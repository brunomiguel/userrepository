{
  "manifest": {
    "name": "stream-buffers",
    "version": "2.2.0",
    "description": "Buffer-backed Streams for reading and writing.",
    "keywords": [
      "memory streams",
      "streams",
      "buffer streams"
    ],
    "author": {
      "name": "Sam Day",
      "email": "me@samcday.com.au"
    },
    "main": "./lib/streambuffer.js",
    "engines": {
      "node": ">= 0.10.0"
    },
    "dependencies": {},
    "devDependencies": {
      "istanbul": "~0.3.2",
      "vows": ">= 0.5.6"
    },
    "license": "Unlicense",
    "repository": {
      "type": "git",
      "url": "https://github.com/samcday/node-stream-buffer.git"
    },
    "scripts": {
      "test": "[ -n \"$NO_COVERAGE\" ] && vows --spec || istanbul cover vows -- --spec"
    },
    "_registry": "npm",
    "_loc": "/home/brunomiguel/userrepository/pkgbuild/cerebro/src/yarn-cache/v6/npm-stream-buffers-2.2.0-91d5f5130d1cef96dcfa7f726945188741d09ee4-integrity/node_modules/stream-buffers/package.json",
    "readmeFilename": "README.md",
    "readme": "# Node Stream Buffers\n\n[![Build Status][badge-travis-img]][badge-travis-url]\n[![Code Climate][badge-climate-img]][badge-climate-url]\n[![Code Coverage][badge-coverage-img]][badge-coverage-url]\n\nSimple Readable and Writable Streams that use a [Buffer][node-buffer-docs] to store received data, or for data to send out. Useful for test code, debugging, and a wide range of other utilities.\n\n## Installation\n\n[![NPM][badge-npm-img]][badge-npm-url]\n\n## Usage\n\nTo use the stream buffers in your module, simply import it and away you go.\n\n```js\nvar streamBuffers = require(\"stream-buffers\");\n```\n\n### Writable StreamBuffer\n\nWritable Stream Buffers implement the standardized writable stream interface. All write()'s to this object will accumulate in an internal Buffer. If the Buffer overflows it will be resized larger automatically. The initial size of the Buffer and the amount in which it grows can be configured in the constructor.\n\n```js\nvar myWritableStreamBuffer = new streamBuffers.WritableStreamBuffer({\n\tinitialSize: (100 * 1024),\t\t// start as 100 kilobytes.\n\tincrementAmount: (10 * 1024)\t// grow by 10 kilobytes each time buffer overflows.\n});\n```\n\nThe default initial size and increment amount are stored in the following constants:\n\n```js\nstreamBuffers.DEFAULT_INITIAL_SIZE \t\t// (8 * 1024)\nstreamBuffers.DEFAULT_INCREMENT_AMOUNT\t// (8 * 1024)\n```\n\nWriting is standard Stream stuff:\n\n```js\nmyWritableStreamBuffer.write(myBuffer);\n// - or -\nmyWritableStreamBuffer.write(\"\\u00bd + \\u00bc = \\u00be\", \"utf8\");\n```\n\nYou can query the size of the data being held in the Buffer, and also how big the Buffer's max capacity currently is: \n\n```js\nmyWritableStreamBuffer.write(\"ASDF\");\nstreamBuffers.size();\t\t\t// 4.\nstreamBuffers.maxSize();\t\t// Whatever was configured as initial size. In our example: (100 * 1024).\n```\n\nRetrieving the contents of the Buffer is simple:\n\n```js\nmyWritableStreamBuffer.getContents();\t\t\t\t\t// Gets all held data as a Buffer.\nmyWritableStreamBuffer.getContentsAsString(\"utf8\");\t\t// Gets all held data as a utf8 string.\nmyWritableStreamBuffer.getContents(5);\t\t\t\t\t// Gets first 5 bytes as a Buffer.\nmyWritableStreamBuffer.getContentsAsString(\"utf8\", 5);\t// Gets first 5 bytes as a utf8 string.\n```\n\nCare should be taken when getting encoded strings from WritableStream, as it doesn't really care about the contents (multi-byte characters will not be respected).\n \nDestroying or ending the WritableStream will not delete the contents of Buffer, but will disallow any further writes:\n\n```js\nmyWritableStreamBuffer.write(\"ASDF\");\nmyWritableStreamBuffer.destroy();\n\nmyWritableStreamBuffer.getContents();\t\t// Returns ASDF in Buffer.\nmyWritableStreamBuffer.write(\"Yeah?\");\t\t// No effect.\n```\t\n\n### Readable StreamBuffer\n\nReadable Stream Buffers can have data inserted in them, which will then be pumped out via standard readable stream data events. The data to be sent out is held in a Buffer, which can grow in much the same way as a WritableStream Buffer does, if data is being put in Buffer faster than it's being pumped out. \n\nThe frequency in which chunks are pumped out, and the size of the chunks themselves can be configured in the constructor. The initial size and increment amount of internal Buffer can be configured too.\n\n```js\nvar myReadableStreamBuffer = new streamBuffers.ReadableStreamBuffer({\n\tfrequency: 10,\t\t// in milliseconds.\n\tchunkSize: 2048\t\t// in bytes.\n});\n```\n\nDefault frequency and chunk size:\n\n```js\nstreamBuffers.DEFAULT_CHUNK_SIZE \t\t// (1024)\nstreamBuffers.DEFAULT_FREQUENCY\t\t\t// (1)\n```\n\nPutting data in Buffer to be pumped out is easy:\n\n```js\nmyReadableStreamBuffer.put(aBuffer);\nmyReadableStreamBuffer.put(\"A String\", \"utf8\");\n```\n\nChunks are pumped out via standard readable stream spec: \n\n```js\nmyReadableStreamBuffer.on(\"data\", function(data) {\n\t// Yup.\n\tassert.isTrue(data instanceof Buffer);\n});\n```\n\nChunks are pumped out by the interval that you specified in frequency. Setting the frequency to 0 will immediately stream the data (also in chunks), even if the stream has not been piped to a destination. This is useful for unit testing. \n\nsetEncoding() for streams is respected too:\n\n```js\nmyReadableStreamBuffer.setEncoding(\"utf8\");\nmyReadableStreamBuffer.on(\"data\", function(data) {\n\tassert.isTrue(data instanceof String);\n});\n```\n\nPause and resume are also implemented. pause()'ing stream will allow buffer to continue accumulating, but will not pump any of that data out until it is resume()'d again. \n\nDestroying the stream will immediately purge the buffer, unless destroySoon() is called, in which case the rest of the buffer will be written out. Either way, any further attempts to put data in the Buffer will be silently ignored. \n\n```js\nmyReadableStreamBuffer.destroySoon();\nmyReadableStreamBuffer.put(\"A String!\");\nmyReadableStreamBuffer.size();\t\t\t// will be 0.\n```\n\n## Disclaimer\n\nNot supposed to be a speed demon, it's more for tests/debugging or weird edge cases. It works with an internal buffer that it copies contents to/from/around.\n\n## Contributors\n\nThanks to the following people for taking some time to contribute to this project.\n\n * Igor Dralyuk <idralyuk@ebay.com>\n * Simon Koudijs <simon.koudijs@intellifi.nl>\n\n## License\n\nnode-stream-buffer is free and unencumbered public domain software. For more information, see the accompanying UNLICENSE file.\n\n[badge-travis-img]: http://img.shields.io/travis/samcday/node-stream-buffer.svg?style=flat-square\n[badge-travis-url]: https://travis-ci.org/samcday/node-stream-buffer\n[badge-climate-img]: http://img.shields.io/codeclimate/github/samcday/node-stream-buffer.svg?style=flat-square\n[badge-climate-url]: https://codeclimate.com/github/samcday/node-stream-buffer\n[badge-coverage-img]: http://img.shields.io/codeclimate/coverage/github/samcday/node-stream-buffer.svg?style=flat-square\n[badge-coverage-url]: https://codeclimate.com/github/samcday/node-stream-buffer\n[badge-npm-img]: https://nodei.co/npm/stream-buffers.png?downloads=true&downloadRank=true&stars=true\n[badge-npm-url]: https://npmjs.org/package/stream-buffers\n\n[node-buffer-docs]: http://nodejs.org/api/buffer.html\n",
    "licenseText": "This is free and unencumbered software released into the public domain.\n\nAnyone is free to copy, modify, publish, use, compile, sell, or\ndistribute this software, either in source code form or as a compiled\nbinary, for any purpose, commercial or non-commercial, and by any\nmeans.\n\nIn jurisdictions that recognize copyright laws, the author or authors\nof this software dedicate any and all copyright interest in the\nsoftware to the public domain. We make this dedication for the benefit\nof the public at large and to the detriment of our heirs and\nsuccessors. We intend this dedication to be an overt act of\nrelinquishment in perpetuity of all present and future rights to this\nsoftware under copyright law.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\nOTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n\nFor more information, please refer to <http://unlicense.org/>"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/stream-buffers/-/stream-buffers-2.2.0.tgz#91d5f5130d1cef96dcfa7f726945188741d09ee4",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/stream-buffers/-/stream-buffers-2.2.0.tgz",
    "hash": "91d5f5130d1cef96dcfa7f726945188741d09ee4",
    "integrity": "sha512-uyQK/mx5QjHun80FLJTfaWE7JtwfRMKBLkMne6udYOmvH0CawotVa7TfgYHzAnpphn4+TweIx1QKMnRIbipmUg==",
    "registry": "npm",
    "packageName": "stream-buffers",
    "cacheIntegrity": "sha512-uyQK/mx5QjHun80FLJTfaWE7JtwfRMKBLkMne6udYOmvH0CawotVa7TfgYHzAnpphn4+TweIx1QKMnRIbipmUg== sha1-kdX1Ew0c75bc+n9yaUUYh0HQnuQ="
  },
  "registry": "npm",
  "hash": "91d5f5130d1cef96dcfa7f726945188741d09ee4"
}