{
  "manifest": {
    "name": "minipass",
    "version": "4.0.0",
    "description": "minimal implementation of a PassThrough stream",
    "main": "index.js",
    "types": "index.d.ts",
    "dependencies": {
      "yallist": "^4.0.0"
    },
    "devDependencies": {
      "@types/node": "^17.0.41",
      "end-of-stream": "^1.4.0",
      "prettier": "^2.6.2",
      "tap": "^16.2.0",
      "through2": "^2.0.3",
      "ts-node": "^10.8.1",
      "typescript": "^4.7.3"
    },
    "scripts": {
      "test": "tap",
      "preversion": "npm test",
      "postversion": "npm publish",
      "postpublish": "git push origin --follow-tags"
    },
    "repository": {
      "type": "git",
      "url": "git+https://github.com/isaacs/minipass.git"
    },
    "keywords": [
      "passthrough",
      "stream"
    ],
    "author": {
      "name": "Isaac Z. Schlueter",
      "email": "i@izs.me",
      "url": "http://blog.izs.me/"
    },
    "license": "ISC",
    "files": [
      "index.d.ts",
      "index.js"
    ],
    "tap": {
      "check-coverage": true
    },
    "engines": {
      "node": ">=8"
    },
    "prettier": {
      "semi": false,
      "printWidth": 80,
      "tabWidth": 2,
      "useTabs": false,
      "singleQuote": true,
      "jsxSingleQuote": false,
      "bracketSameLine": true,
      "arrowParens": "avoid",
      "endOfLine": "lf"
    },
    "_registry": "npm",
    "_loc": "/home/brunomiguel/userrepository/pkgbuild/cerebro/src/yarn-cache/v6/npm-minipass-4.0.0-7cebb0f9fa7d56f0c5b17853cbe28838a8dbbd3b-integrity/node_modules/minipass/package.json",
    "readmeFilename": "README.md",
    "readme": "# minipass\n\nA _very_ minimal implementation of a [PassThrough\nstream](https://nodejs.org/api/stream.html#stream_class_stream_passthrough)\n\n[It's very\nfast](https://docs.google.com/spreadsheets/d/1oObKSrVwLX_7Ut4Z6g3fZW-AX1j1-k6w-cDsrkaSbHM/edit#gid=0)\nfor objects, strings, and buffers.\n\nSupports `pipe()`ing (including multi-`pipe()` and backpressure transmission),\nbuffering data until either a `data` event handler or `pipe()` is added (so\nyou don't lose the first chunk), and most other cases where PassThrough is\na good idea.\n\nThere is a `read()` method, but it's much more efficient to consume data\nfrom this stream via `'data'` events or by calling `pipe()` into some other\nstream.  Calling `read()` requires the buffer to be flattened in some\ncases, which requires copying memory.\n\nIf you set `objectMode: true` in the options, then whatever is written will\nbe emitted.  Otherwise, it'll do a minimal amount of Buffer copying to\nensure proper Streams semantics when `read(n)` is called.\n\n`objectMode` can also be set by doing `stream.objectMode = true`, or by\nwriting any non-string/non-buffer data.  `objectMode` cannot be set to\nfalse once it is set.\n\nThis is not a `through` or `through2` stream.  It doesn't transform the\ndata, it just passes it right through.  If you want to transform the data,\nextend the class, and override the `write()` method.  Once you're done\ntransforming the data however you want, call `super.write()` with the\ntransform output.\n\nFor some examples of streams that extend Minipass in various ways, check\nout:\n\n- [minizlib](http://npm.im/minizlib)\n- [fs-minipass](http://npm.im/fs-minipass)\n- [tar](http://npm.im/tar)\n- [minipass-collect](http://npm.im/minipass-collect)\n- [minipass-flush](http://npm.im/minipass-flush)\n- [minipass-pipeline](http://npm.im/minipass-pipeline)\n- [tap](http://npm.im/tap)\n- [tap-parser](http://npm.im/tap-parser)\n- [treport](http://npm.im/treport)\n- [minipass-fetch](http://npm.im/minipass-fetch)\n- [pacote](http://npm.im/pacote)\n- [make-fetch-happen](http://npm.im/make-fetch-happen)\n- [cacache](http://npm.im/cacache)\n- [ssri](http://npm.im/ssri)\n- [npm-registry-fetch](http://npm.im/npm-registry-fetch)\n- [minipass-json-stream](http://npm.im/minipass-json-stream)\n- [minipass-sized](http://npm.im/minipass-sized)\n\n## Differences from Node.js Streams\n\nThere are several things that make Minipass streams different from (and in\nsome ways superior to) Node.js core streams.\n\nPlease read these caveats if you are familiar with node-core streams and\nintend to use Minipass streams in your programs.\n\nYou can avoid most of these differences entirely (for a very\nsmall performance penalty) by setting `{async: true}` in the\nconstructor options.\n\n### Timing\n\nMinipass streams are designed to support synchronous use-cases.  Thus, data\nis emitted as soon as it is available, always.  It is buffered until read,\nbut no longer.  Another way to look at it is that Minipass streams are\nexactly as synchronous as the logic that writes into them.\n\nThis can be surprising if your code relies on `PassThrough.write()` always\nproviding data on the next tick rather than the current one, or being able\nto call `resume()` and not have the entire buffer disappear immediately.\n\nHowever, without this synchronicity guarantee, there would be no way for\nMinipass to achieve the speeds it does, or support the synchronous use\ncases that it does.  Simply put, waiting takes time.\n\nThis non-deferring approach makes Minipass streams much easier to reason\nabout, especially in the context of Promises and other flow-control\nmechanisms.\n\nExample:\n\n```js\nconst Minipass = require('minipass')\nconst stream = new Minipass({ async: true })\nstream.on('data', () => console.log('data event'))\nconsole.log('before write')\nstream.write('hello')\nconsole.log('after write')\n// output:\n// before write\n// data event\n// after write\n```\n\n### Exception: Async Opt-In\n\nIf you wish to have a Minipass stream with behavior that more\nclosely mimics Node.js core streams, you can set the stream in\nasync mode either by setting `async: true` in the constructor\noptions, or by setting `stream.async = true` later on.\n\n```js\nconst Minipass = require('minipass')\nconst asyncStream = new Minipass({ async: true })\nasyncStream.on('data', () => console.log('data event'))\nconsole.log('before write')\nasyncStream.write('hello')\nconsole.log('after write')\n// output:\n// before write\n// after write\n// data event <-- this is deferred until the next tick\n```\n\nSwitching _out_ of async mode is unsafe, as it could cause data\ncorruption, and so is not enabled.  Example:\n\n```js\nconst Minipass = require('minipass')\nconst stream = new Minipass({ encoding: 'utf8' })\nstream.on('data', chunk => console.log(chunk))\nstream.async = true\nconsole.log('before writes')\nstream.write('hello')\nsetStreamSyncAgainSomehow(stream) // <-- this doesn't actually exist!\nstream.write('world')\nconsole.log('after writes')\n// hypothetical output would be:\n// before writes\n// world\n// after writes\n// hello\n// NOT GOOD!\n```\n\nTo avoid this problem, once set into async mode, any attempt to\nmake the stream sync again will be ignored.\n\n```js\nconst Minipass = require('minipass')\nconst stream = new Minipass({ encoding: 'utf8' })\nstream.on('data', chunk => console.log(chunk))\nstream.async = true\nconsole.log('before writes')\nstream.write('hello')\nstream.async = false // <-- no-op, stream already async\nstream.write('world')\nconsole.log('after writes')\n// actual output:\n// before writes\n// after writes\n// hello\n// world\n```\n\n### No High/Low Water Marks\n\nNode.js core streams will optimistically fill up a buffer, returning `true`\non all writes until the limit is hit, even if the data has nowhere to go.\nThen, they will not attempt to draw more data in until the buffer size dips\nbelow a minimum value.\n\nMinipass streams are much simpler.  The `write()` method will return `true`\nif the data has somewhere to go (which is to say, given the timing\nguarantees, that the data is already there by the time `write()` returns).\n\nIf the data has nowhere to go, then `write()` returns false, and the data\nsits in a buffer, to be drained out immediately as soon as anyone consumes\nit.\n\nSince nothing is ever buffered unnecessarily, there is much less\ncopying data, and less bookkeeping about buffer capacity levels.\n\n### Hazards of Buffering (or: Why Minipass Is So Fast)\n\nSince data written to a Minipass stream is immediately written all the way\nthrough the pipeline, and `write()` always returns true/false based on\nwhether the data was fully flushed, backpressure is communicated\nimmediately to the upstream caller.  This minimizes buffering.\n\nConsider this case:\n\n```js\nconst {PassThrough} = require('stream')\nconst p1 = new PassThrough({ highWaterMark: 1024 })\nconst p2 = new PassThrough({ highWaterMark: 1024 })\nconst p3 = new PassThrough({ highWaterMark: 1024 })\nconst p4 = new PassThrough({ highWaterMark: 1024 })\n\np1.pipe(p2).pipe(p3).pipe(p4)\np4.on('data', () => console.log('made it through'))\n\n// this returns false and buffers, then writes to p2 on next tick (1)\n// p2 returns false and buffers, pausing p1, then writes to p3 on next tick (2)\n// p3 returns false and buffers, pausing p2, then writes to p4 on next tick (3)\n// p4 returns false and buffers, pausing p3, then emits 'data' and 'drain'\n// on next tick (4)\n// p3 sees p4's 'drain' event, and calls resume(), emitting 'resume' and\n// 'drain' on next tick (5)\n// p2 sees p3's 'drain', calls resume(), emits 'resume' and 'drain' on next tick (6)\n// p1 sees p2's 'drain', calls resume(), emits 'resume' and 'drain' on next\n// tick (7)\n\np1.write(Buffer.alloc(2048)) // returns false\n```\n\nAlong the way, the data was buffered and deferred at each stage, and\nmultiple event deferrals happened, for an unblocked pipeline where it was\nperfectly safe to write all the way through!\n\nFurthermore, setting a `highWaterMark` of `1024` might lead someone reading\nthe code to think an advisory maximum of 1KiB is being set for the\npipeline.  However, the actual advisory buffering level is the _sum_ of\n`highWaterMark` values, since each one has its own bucket.\n\nConsider the Minipass case:\n\n```js\nconst m1 = new Minipass()\nconst m2 = new Minipass()\nconst m3 = new Minipass()\nconst m4 = new Minipass()\n\nm1.pipe(m2).pipe(m3).pipe(m4)\nm4.on('data', () => console.log('made it through'))\n\n// m1 is flowing, so it writes the data to m2 immediately\n// m2 is flowing, so it writes the data to m3 immediately\n// m3 is flowing, so it writes the data to m4 immediately\n// m4 is flowing, so it fires the 'data' event immediately, returns true\n// m4's write returned true, so m3 is still flowing, returns true\n// m3's write returned true, so m2 is still flowing, returns true\n// m2's write returned true, so m1 is still flowing, returns true\n// No event deferrals or buffering along the way!\n\nm1.write(Buffer.alloc(2048)) // returns true\n```\n\nIt is extremely unlikely that you _don't_ want to buffer any data written,\nor _ever_ buffer data that can be flushed all the way through.  Neither\nnode-core streams nor Minipass ever fail to buffer written data, but\nnode-core streams do a lot of unnecessary buffering and pausing.\n\nAs always, the faster implementation is the one that does less stuff and\nwaits less time to do it.\n\n### Immediately emit `end` for empty streams (when not paused)\n\nIf a stream is not paused, and `end()` is called before writing any data\ninto it, then it will emit `end` immediately.\n\nIf you have logic that occurs on the `end` event which you don't want to\npotentially happen immediately (for example, closing file descriptors,\nmoving on to the next entry in an archive parse stream, etc.) then be sure\nto call `stream.pause()` on creation, and then `stream.resume()` once you\nare ready to respond to the `end` event.\n\nHowever, this is _usually_ not a problem because:\n\n### Emit `end` When Asked\n\nOne hazard of immediately emitting `'end'` is that you may not yet have had\na chance to add a listener.  In order to avoid this hazard, Minipass\nstreams safely re-emit the `'end'` event if a new listener is added after\n`'end'` has been emitted.\n\nIe, if you do `stream.on('end', someFunction)`, and the stream has already\nemitted `end`, then it will call the handler right away.  (You can think of\nthis somewhat like attaching a new `.then(fn)` to a previously-resolved\nPromise.)\n\nTo prevent calling handlers multiple times who would not expect multiple\nends to occur, all listeners are removed from the `'end'` event whenever it\nis emitted.\n\n### Emit `error` When Asked\n\nThe most recent error object passed to the `'error'` event is\nstored on the stream.  If a new `'error'` event handler is added,\nand an error was previously emitted, then the event handler will\nbe called immediately (or on `process.nextTick` in the case of\nasync streams).\n\nThis makes it much more difficult to end up trying to interact\nwith a broken stream, if the error handler is added after an\nerror was previously emitted.\n\n### Impact of \"immediate flow\" on Tee-streams\n\nA \"tee stream\" is a stream piping to multiple destinations:\n\n```js\nconst tee = new Minipass()\nt.pipe(dest1)\nt.pipe(dest2)\nt.write('foo') // goes to both destinations\n```\n\nSince Minipass streams _immediately_ process any pending data through the\npipeline when a new pipe destination is added, this can have surprising\neffects, especially when a stream comes in from some other function and may\nor may not have data in its buffer.\n\n```js\n// WARNING! WILL LOSE DATA!\nconst src = new Minipass()\nsrc.write('foo')\nsrc.pipe(dest1) // 'foo' chunk flows to dest1 immediately, and is gone\nsrc.pipe(dest2) // gets nothing!\n```\n\nOne solution is to create a dedicated tee-stream junction that pipes to\nboth locations, and then pipe to _that_ instead.\n\n```js\n// Safe example: tee to both places\nconst src = new Minipass()\nsrc.write('foo')\nconst tee = new Minipass()\ntee.pipe(dest1)\ntee.pipe(dest2)\nsrc.pipe(tee) // tee gets 'foo', pipes to both locations\n```\n\nThe same caveat applies to `on('data')` event listeners.  The first one\nadded will _immediately_ receive all of the data, leaving nothing for the\nsecond:\n\n```js\n// WARNING! WILL LOSE DATA!\nconst src = new Minipass()\nsrc.write('foo')\nsrc.on('data', handler1) // receives 'foo' right away\nsrc.on('data', handler2) // nothing to see here!\n```\n\nUsing a dedicated tee-stream can be used in this case as well:\n\n```js\n// Safe example: tee to both data handlers\nconst src = new Minipass()\nsrc.write('foo')\nconst tee = new Minipass()\ntee.on('data', handler1)\ntee.on('data', handler2)\nsrc.pipe(tee)\n```\n\nAll of the hazards in this section are avoided by setting `{\nasync: true }` in the Minipass constructor, or by setting\n`stream.async = true` afterwards.  Note that this does add some\noverhead, so should only be done in cases where you are willing\nto lose a bit of performance in order to avoid having to refactor\nprogram logic.\n\n## USAGE\n\nIt's a stream!  Use it like a stream and it'll most likely do what you\nwant.\n\n```js\nconst Minipass = require('minipass')\nconst mp = new Minipass(options) // optional: { encoding, objectMode }\nmp.write('foo')\nmp.pipe(someOtherStream)\nmp.end('bar')\n```\n\n### OPTIONS\n\n* `encoding` How would you like the data coming _out_ of the stream to be\n  encoded?  Accepts any values that can be passed to `Buffer.toString()`.\n* `objectMode` Emit data exactly as it comes in.  This will be flipped on\n  by default if you write() something other than a string or Buffer at any\n  point.  Setting `objectMode: true` will prevent setting any encoding\n  value.\n* `async` Defaults to `false`.  Set to `true` to defer data\n  emission until next tick.  This reduces performance slightly,\n  but makes Minipass streams use timing behavior closer to Node\n  core streams.  See [Timing](#timing) for more details.\n\n### API\n\nImplements the user-facing portions of Node.js's `Readable` and `Writable`\nstreams.\n\n### Methods\n\n* `write(chunk, [encoding], [callback])` - Put data in.  (Note that, in the\n  base Minipass class, the same data will come out.)  Returns `false` if\n  the stream will buffer the next write, or true if it's still in \"flowing\"\n  mode.\n* `end([chunk, [encoding]], [callback])` - Signal that you have no more\n  data to write.  This will queue an `end` event to be fired when all the\n  data has been consumed.\n* `setEncoding(encoding)` - Set the encoding for data coming of the stream.\n  This can only be done once.\n* `pause()` - No more data for a while, please.  This also prevents `end`\n  from being emitted for empty streams until the stream is resumed.\n* `resume()` - Resume the stream.  If there's data in the buffer, it is all\n  discarded.  Any buffered events are immediately emitted.\n* `pipe(dest)` - Send all output to the stream provided.  When\n  data is emitted, it is immediately written to any and all pipe\n  destinations.  (Or written on next tick in `async` mode.)\n* `unpipe(dest)` - Stop piping to the destination stream.  This\n  is immediate, meaning that any asynchronously queued data will\n  _not_ make it to the destination when running in `async` mode.\n    * `options.end` - Boolean, end the destination stream when\n      the source stream ends.  Default `true`.\n    * `options.proxyErrors` - Boolean, proxy `error` events from\n      the source stream to the destination stream.  Note that\n      errors are _not_ proxied after the pipeline terminates,\n      either due to the source emitting `'end'` or manually\n      unpiping with `src.unpipe(dest)`.  Default `false`.\n* `on(ev, fn)`, `emit(ev, fn)` - Minipass streams are EventEmitters.  Some\n  events are given special treatment, however.  (See below under \"events\".)\n* `promise()` - Returns a Promise that resolves when the stream emits\n  `end`, or rejects if the stream emits `error`.\n* `collect()` - Return a Promise that resolves on `end` with an array\n  containing each chunk of data that was emitted, or rejects if the stream\n  emits `error`.  Note that this consumes the stream data.\n* `concat()` - Same as `collect()`, but concatenates the data into a single\n  Buffer object.  Will reject the returned promise if the stream is in\n  objectMode, or if it goes into objectMode by the end of the data.\n* `read(n)` - Consume `n` bytes of data out of the buffer.  If `n` is not\n  provided, then consume all of it.  If `n` bytes are not available, then\n  it returns null.  **Note** consuming streams in this way is less\n  efficient, and can lead to unnecessary Buffer copying.\n* `destroy([er])` - Destroy the stream.  If an error is provided, then an\n  `'error'` event is emitted.  If the stream has a `close()` method, and\n  has not emitted a `'close'` event yet, then `stream.close()` will be\n  called.  Any Promises returned by `.promise()`, `.collect()` or\n  `.concat()` will be rejected.  After being destroyed, writing to the\n  stream will emit an error.  No more data will be emitted if the stream is\n  destroyed, even if it was previously buffered.\n\n### Properties\n\n* `bufferLength` Read-only.  Total number of bytes buffered, or in the case\n  of objectMode, the total number of objects.\n* `encoding` The encoding that has been set.  (Setting this is equivalent\n  to calling `setEncoding(enc)` and has the same prohibition against\n  setting multiple times.)\n* `flowing` Read-only.  Boolean indicating whether a chunk written to the\n  stream will be immediately emitted.\n* `emittedEnd` Read-only.  Boolean indicating whether the end-ish events\n  (ie, `end`, `prefinish`, `finish`) have been emitted.  Note that\n  listening on any end-ish event will immediateyl re-emit it if it has\n  already been emitted.\n* `writable` Whether the stream is writable.  Default `true`.  Set to\n  `false` when `end()`\n* `readable` Whether the stream is readable.  Default `true`.\n* `buffer` A [yallist](http://npm.im/yallist) linked list of chunks written\n  to the stream that have not yet been emitted.  (It's probably a bad idea\n  to mess with this.)\n* `pipes` A [yallist](http://npm.im/yallist) linked list of streams that\n  this stream is piping into.  (It's probably a bad idea to mess with\n  this.)\n* `destroyed` A getter that indicates whether the stream was destroyed.\n* `paused` True if the stream has been explicitly paused, otherwise false.\n* `objectMode` Indicates whether the stream is in `objectMode`.  Once set\n  to `true`, it cannot be set to `false`.\n\n### Events\n\n* `data` Emitted when there's data to read.  Argument is the data to read.\n  This is never emitted while not flowing.  If a listener is attached, that\n  will resume the stream.\n* `end` Emitted when there's no more data to read.  This will be emitted\n  immediately for empty streams when `end()` is called.  If a listener is\n  attached, and `end` was already emitted, then it will be emitted again.\n  All listeners are removed when `end` is emitted.\n* `prefinish` An end-ish event that follows the same logic as `end` and is\n  emitted in the same conditions where `end` is emitted.  Emitted after\n  `'end'`.\n* `finish` An end-ish event that follows the same logic as `end` and is\n  emitted in the same conditions where `end` is emitted.  Emitted after\n  `'prefinish'`.\n* `close` An indication that an underlying resource has been released.\n  Minipass does not emit this event, but will defer it until after `end`\n  has been emitted, since it throws off some stream libraries otherwise.\n* `drain` Emitted when the internal buffer empties, and it is again\n  suitable to `write()` into the stream.\n* `readable` Emitted when data is buffered and ready to be read by a\n  consumer.\n* `resume` Emitted when stream changes state from buffering to flowing\n  mode.  (Ie, when `resume` is called, `pipe` is called, or a `data` event\n  listener is added.)\n\n### Static Methods\n\n* `Minipass.isStream(stream)` Returns `true` if the argument is a stream,\n  and false otherwise.  To be considered a stream, the object must be\n  either an instance of Minipass, or an EventEmitter that has either a\n  `pipe()` method, or both `write()` and `end()` methods.  (Pretty much any\n  stream in node-land will return `true` for this.)\n\n## EXAMPLES\n\nHere are some examples of things you can do with Minipass streams.\n\n### simple \"are you done yet\" promise\n\n```js\nmp.promise().then(() => {\n  // stream is finished\n}, er => {\n  // stream emitted an error\n})\n```\n\n### collecting\n\n```js\nmp.collect().then(all => {\n  // all is an array of all the data emitted\n  // encoding is supported in this case, so\n  // so the result will be a collection of strings if\n  // an encoding is specified, or buffers/objects if not.\n  //\n  // In an async function, you may do\n  // const data = await stream.collect()\n})\n```\n\n### collecting into a single blob\n\nThis is a bit slower because it concatenates the data into one chunk for\nyou, but if you're going to do it yourself anyway, it's convenient this\nway:\n\n```js\nmp.concat().then(onebigchunk => {\n  // onebigchunk is a string if the stream\n  // had an encoding set, or a buffer otherwise.\n})\n```\n\n### iteration\n\nYou can iterate over streams synchronously or asynchronously in platforms\nthat support it.\n\nSynchronous iteration will end when the currently available data is\nconsumed, even if the `end` event has not been reached.  In string and\nbuffer mode, the data is concatenated, so unless multiple writes are\noccurring in the same tick as the `read()`, sync iteration loops will\ngenerally only have a single iteration.\n\nTo consume chunks in this way exactly as they have been written, with no\nflattening, create the stream with the `{ objectMode: true }` option.\n\n```js\nconst mp = new Minipass({ objectMode: true })\nmp.write('a')\nmp.write('b')\nfor (let letter of mp) {\n  console.log(letter) // a, b\n}\nmp.write('c')\nmp.write('d')\nfor (let letter of mp) {\n  console.log(letter) // c, d\n}\nmp.write('e')\nmp.end()\nfor (let letter of mp) {\n  console.log(letter) // e\n}\nfor (let letter of mp) {\n  console.log(letter) // nothing\n}\n```\n\nAsynchronous iteration will continue until the end event is reached,\nconsuming all of the data.\n\n```js\nconst mp = new Minipass({ encoding: 'utf8' })\n\n// some source of some data\nlet i = 5\nconst inter = setInterval(() => {\n  if (i-- > 0)\n    mp.write(Buffer.from('foo\\n', 'utf8'))\n  else {\n    mp.end()\n    clearInterval(inter)\n  }\n}, 100)\n\n// consume the data with asynchronous iteration\nasync function consume () {\n  for await (let chunk of mp) {\n    console.log(chunk)\n  }\n  return 'ok'\n}\n\nconsume().then(res => console.log(res))\n// logs `foo\\n` 5 times, and then `ok`\n```\n\n### subclass that `console.log()`s everything written into it\n\n```js\nclass Logger extends Minipass {\n  write (chunk, encoding, callback) {\n    console.log('WRITE', chunk, encoding)\n    return super.write(chunk, encoding, callback)\n  }\n  end (chunk, encoding, callback) {\n    console.log('END', chunk, encoding)\n    return super.end(chunk, encoding, callback)\n  }\n}\n\nsomeSource.pipe(new Logger()).pipe(someDest)\n```\n\n### same thing, but using an inline anonymous class\n\n```js\n// js classes are fun\nsomeSource\n  .pipe(new (class extends Minipass {\n    emit (ev, ...data) {\n      // let's also log events, because debugging some weird thing\n      console.log('EMIT', ev)\n      return super.emit(ev, ...data)\n    }\n    write (chunk, encoding, callback) {\n      console.log('WRITE', chunk, encoding)\n      return super.write(chunk, encoding, callback)\n    }\n    end (chunk, encoding, callback) {\n      console.log('END', chunk, encoding)\n      return super.end(chunk, encoding, callback)\n    }\n  }))\n  .pipe(someDest)\n```\n\n### subclass that defers 'end' for some reason\n\n```js\nclass SlowEnd extends Minipass {\n  emit (ev, ...args) {\n    if (ev === 'end') {\n      console.log('going to end, hold on a sec')\n      setTimeout(() => {\n        console.log('ok, ready to end now')\n        super.emit('end', ...args)\n      }, 100)\n    } else {\n      return super.emit(ev, ...args)\n    }\n  }\n}\n```\n\n### transform that creates newline-delimited JSON\n\n```js\nclass NDJSONEncode extends Minipass {\n  write (obj, cb) {\n    try {\n      // JSON.stringify can throw, emit an error on that\n      return super.write(JSON.stringify(obj) + '\\n', 'utf8', cb)\n    } catch (er) {\n      this.emit('error', er)\n    }\n  }\n  end (obj, cb) {\n    if (typeof obj === 'function') {\n      cb = obj\n      obj = undefined\n    }\n    if (obj !== undefined) {\n      this.write(obj)\n    }\n    return super.end(cb)\n  }\n}\n```\n\n### transform that parses newline-delimited JSON\n\n```js\nclass NDJSONDecode extends Minipass {\n  constructor (options) {\n    // always be in object mode, as far as Minipass is concerned\n    super({ objectMode: true })\n    this._jsonBuffer = ''\n  }\n  write (chunk, encoding, cb) {\n    if (typeof chunk === 'string' &&\n        typeof encoding === 'string' &&\n        encoding !== 'utf8') {\n      chunk = Buffer.from(chunk, encoding).toString()\n    } else if (Buffer.isBuffer(chunk))\n      chunk = chunk.toString()\n    }\n    if (typeof encoding === 'function') {\n      cb = encoding\n    }\n    const jsonData = (this._jsonBuffer + chunk).split('\\n')\n    this._jsonBuffer = jsonData.pop()\n    for (let i = 0; i < jsonData.length; i++) {\n      try {\n        // JSON.parse can throw, emit an error on that\n        super.write(JSON.parse(jsonData[i]))\n      } catch (er) {\n        this.emit('error', er)\n        continue\n      }\n    }\n    if (cb)\n      cb()\n  }\n}\n```\n",
    "licenseText": "The ISC License\n\nCopyright (c) 2017-2022 npm, Inc., Isaac Z. Schlueter, and Contributors\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted, provided that the above\ncopyright notice and this permission notice appear in all copies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\nWITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\nANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR\nIN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/minipass/-/minipass-4.0.0.tgz#7cebb0f9fa7d56f0c5b17853cbe28838a8dbbd3b",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/minipass/-/minipass-4.0.0.tgz",
    "hash": "7cebb0f9fa7d56f0c5b17853cbe28838a8dbbd3b",
    "integrity": "sha512-g2Uuh2jEKoht+zvO6vJqXmYpflPqzRBT+Th2h01DKh5z7wbY/AZ2gCQ78cP70YoHPyFdY30YBV5WxgLOEwOykw==",
    "registry": "npm",
    "packageName": "minipass",
    "cacheIntegrity": "sha512-g2Uuh2jEKoht+zvO6vJqXmYpflPqzRBT+Th2h01DKh5z7wbY/AZ2gCQ78cP70YoHPyFdY30YBV5WxgLOEwOykw== sha1-fOuw+fp9VvDFsXhTy+KIOKjbvTs="
  },
  "registry": "npm",
  "hash": "7cebb0f9fa7d56f0c5b17853cbe28838a8dbbd3b"
}