{
  "manifest": {
    "name": "fflate",
    "version": "0.4.8",
    "description": "High performance (de)compression in an 8kB package",
    "main": "./lib/index.js",
    "module": "./esm/index.mjs",
    "types": "./lib/index.d.ts",
    "unpkg": "./umd/index.js",
    "jsdelivr": "./umd/index.js",
    "browser": {
      "./lib/node-worker.js": "./lib/worker.js",
      "./esm/index.mjs": "./esm/browser.js"
    },
    "targets": {
      "main": false,
      "module": false,
      "browser": false,
      "types": false
    },
    "sideEffects": false,
    "homepage": "https://101arrowz.github.io/fflate",
    "repository": {
      "type": "git",
      "url": "https://github.com/101arrowz/fflate"
    },
    "bugs": {
      "email": "arjunbarrett@gmail.com",
      "url": "https://github.com/101arrowz/fflate/issues"
    },
    "author": {
      "name": "Arjun Barrett"
    },
    "license": "MIT",
    "keywords": [
      "gzip",
      "gunzip",
      "deflate",
      "inflate",
      "compression",
      "decompression",
      "zlib",
      "pako",
      "jszip",
      "browser",
      "node.js",
      "tiny",
      "fast",
      "zip",
      "unzip",
      "non-blocking"
    ],
    "scripts": {
      "build": "yarn build:lib && yarn build:docs && yarn build:rewrite && yarn build:demo",
      "script": "node -r ts-node/register scripts/$SC.ts",
      "build:lib": "tsc && tsc --project tsconfig.esm.json && yarn build:umd",
      "build:umd": "SC=buildUMD yarn script",
      "build:rewrite": "SC=rewriteBuilds yarn script",
      "build:demo": "tsc --project tsconfig.demo.json && parcel build demo/index.html --public-url \"./\" && SC=cpGHPages yarn script",
      "build:docs": "typedoc --mode library --plugin typedoc-plugin-markdown --hideProjectName --hideBreadcrumbs --readme none --disableSources --excludePrivate --excludeProtected --out docs/ src/index.ts",
      "test": "TS_NODE_PROJECT=test/tsconfig.json uvu -b -r ts-node/register test",
      "prepack": "yarn build && yarn test"
    },
    "devDependencies": {
      "@types/node": "^14.11.2",
      "@types/pako": "*",
      "@types/react": "^16.9.55",
      "@types/react-dom": "^16.9.9",
      "jszip": "^3.5.0",
      "pako": "*",
      "parcel": "^2.0.0-nightly.440",
      "parcel-config-precache-manifest": "^0.0.3",
      "preact": "^10.5.5",
      "react": "^17.0.1",
      "react-dom": "^17.0.1",
      "rmwc": "^6.1.4",
      "simple-git": "^2.22.0",
      "terser": "^5.3.8",
      "tiny-inflate": "*",
      "ts-node": "^9.0.0",
      "typedoc": "^0.17.0-3",
      "typedoc-plugin-markdown": "^3.0.2",
      "typescript": "^4.0.2",
      "uvu": "^0.3.3",
      "uzip": "*"
    },
    "alias": {
      "react": "preact/compat",
      "react-dom": "preact/compat",
      "react-dom/test-utils": "preact/test-utils"
    },
    "_registry": "npm",
    "_loc": "/home/brunomiguel/userrepository/pkgbuild/cerebro/src/yarn-cache/v6/npm-fflate-0.4.8-f90b82aefbd8ac174213abb338bd7ef848f0f5ae-integrity/node_modules/fflate/package.json",
    "readmeFilename": "README.md",
    "readme": "# fflate\nHigh performance (de)compression in an 8kB package\n\n## Why fflate?\n`fflate` (short for fast flate) is the **fastest, smallest, and most versatile** pure JavaScript compression and decompression library in existence, handily beating [`pako`](https://npmjs.com/package/pako), [`tiny-inflate`](https://npmjs.com/package/tiny-inflate), and [`UZIP.js`](https://github.com/photopea/UZIP.js) in performance benchmarks while being multiple times more lightweight. Its compression ratios are often better than even the original Zlib C library. It includes support for DEFLATE, GZIP, and Zlib data. Data compressed by `fflate` can be decompressed by other tools, and vice versa.\n\nIn addition to the base decompression and compression APIs, `fflate` supports high-speed ZIP file archiving for an extra 3 kB. In fact, the compressor, in synchronous mode, compresses both more quickly and with a higher compression ratio than most compression software (even Info-ZIP, a C program), and in asynchronous mode it can utilize multiple threads to achieve over 3x the performance of any other utility.\n\n|                             | `pako` | `tiny-inflate`         | `UZIP.js`             | `fflate`                       |\n|-----------------------------|--------|------------------------|-----------------------|--------------------------------|\n| Decompression performance   | 1x     | Up to 40% slower       | **Up to 40% faster**  | **Up to 40% faster**           |\n| Compression performance     | 1x     | N/A                    | Up to 5% faster       | **Up to 50% faster**           |\n| Base bundle size (minified) | 45.6kB | **3kB (inflate only)** | 14.2kB                | 8kB **(3kB for inflate only)** |\n| Compression support         | ✅     | ❌                      | ✅                    | ✅                             |\n| Thread/Worker safe          | ✅     | ✅                      | ❌                    | ✅                             |\n| ZIP support                 | ❌     | ❌                      | ✅                    | ✅                             |\n| Streaming support           | ✅     | ❌                      | ❌                    | ✅                             |\n| GZIP/Zlib support           | ✅     | ❌                      | ❌                    | ✅                             |\n| Supports files up to 4GB    | ✅     | ❌                      | ❌                    | ✅                             |\n| Doesn't hang on error       | ✅     | ❌                      | ❌                    | ✅                             |\n| Multi-thread/Asynchronous   | ❌     | ❌                      | ❌                    | ✅                             |\n| Uses ES Modules             | ❌     | ❌                      | ❌                    | ✅                             |\n\n## Demo\nIf you'd like to try `fflate` for yourself without installing it, you can take a look at the [browser demo](https://101arrowz.github.io/fflate). Since `fflate` is a pure JavaScript library, it works in both the browser and Node.js (see [Browser support](https://github.com/101arrowz/fflate/#browser-support) for more info).\n\n## Usage\n\nInstall `fflate`:\n```sh\nnpm i fflate # or yarn add fflate, or pnpm add fflate\n```\n\nImport:\n```js\n// I will assume that you use the following for the rest of this guide\nimport * as fflate from 'fflate';\n\n// However, you should import ONLY what you need to minimize bloat.\n// So, if you just need GZIP compression support:\nimport { gzipSync } from 'fflate';\n// Woo! You just saved 15 kB off your bundle with one line.\n```\n\nIf your environment doesn't support ES Modules (e.g. Node.js):\n```js\n// Try to avoid this when using fflate in the browser, as it will import\n// all of fflate's components, even those that you aren't using.\nconst fflate = require('fflate');\n```\n\nIf you want to load from a CDN in the browser:\n```html\n<!--\nYou should use either UNPKG or jsDelivr (i.e. only one of the following)\nNote that tree shaking is completely unsupported from the CDN\n-->\n<script src=\"https://unpkg.com/fflate\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/fflate/umd/index.js\"></script>\n<!-- Now, the global variable fflate contains the library -->\n```\n\nAnd use:\n```js\n// This is an ArrayBuffer of data\nconst massiveFileBuf = await fetch('/aMassiveFile').then(\n  res => res.arrayBuffer()\n);\n// To use fflate, you need a Uint8Array\nconst massiveFile = new Uint8Array(massiveFileBuf);\n// Note that Node.js Buffers work just fine as well:\n// const massiveFile = require('fs').readFileSync('aMassiveFile.txt');\n\n// Higher level means lower performance but better compression\n// The level ranges from 0 (no compression) to 9 (max compression)\n// The default level is 6\nconst notSoMassive = fflate.zlibSync(massiveFile, { level: 9 });\nconst massiveAgain = fflate.unzlibSync(notSoMassive);\nconst gzipped = fflate.gzipSync(massiveFile, {\n  // GZIP-specific: the filename to use when decompressed\n  filename: 'aMassiveFile.txt',\n  // GZIP-specific: the modification time. Can be a Date, date string,\n  // or Unix timestamp\n  mtime: '9/1/16 2:00 PM'\n});\n```\n`fflate` can autodetect a compressed file's format as well:\n```js\nconst compressed = new Uint8Array(\n  await fetch('/GZIPorZLIBorDEFLATE').then(res => res.arrayBuffer())\n);\n// Above example with Node.js Buffers:\n// Buffer.from('H4sIAAAAAAAAE8tIzcnJBwCGphA2BQAAAA==', 'base64');\n\nconst decompressed = fflate.decompressSync(compressed);\n```\n\nUsing strings is easy with `fflate`'s string conversion API:\n```js\nconst buf = fflate.strToU8('Hello world!');\n\n// The default compression method is gzip\n// Increasing mem may increase performance at the cost of memory\n// The mem ranges from 0 to 12, where 4 is the default\nconst compressed = fflate.compressSync(buf, { level: 6, mem: 8 });\n\n// When you need to decompress:\nconst decompressed = fflate.decompressSync(compressed);\nconst origText = fflate.strFromU8(decompressed);\nconsole.log(origText); // Hello world!\n```\n\nIf you need to use an (albeit inefficient) binary string, you can set the second argument to `true`.\n```js\nconst buf = fflate.strToU8('Hello world!');\n\n// The second argument, latin1, is a boolean that indicates that the data\n// is not Unicode but rather should be encoded and decoded as Latin-1.\n// This is useful for creating a string from binary data that isn't\n// necessarily valid UTF-8. However, binary strings are incredibly\n// inefficient and tend to double file size, so they're not recommended.\nconst compressedString = fflate.strFromU8(\n  fflate.compressSync(buf),\n  true\n);\nconst decompressed = fflate.decompressSync(\n  fflate.strToU8(compressedString, true)\n);\nconst origText = fflate.strFromU8(decompressed);\nconsole.log(origText); // Hello world!\n```\n\nYou can use streams as well to incrementally add data to be compressed or decompressed:\n```js\n// This example uses synchronous streams, but for the best experience\n// you'll definitely want to use asynchronous streams.\n\nlet outStr = '';\nconst gzipStream = new fflate.Gzip({ level: 9 }, (chunk, isLast) => {\n  // accumulate in an inefficient binary string (just an example)\n  outStr += fflate.strFromU8(chunk, true);\n});\n\n// You can also attach the data handler separately if you don't want to\n// do so in the constructor.\ngzipStream.ondata = (chunk, final) => { ... }\n\n// Since this is synchronous, all errors will be thrown by stream.push()\ngzipStream.push(chunk1);\ngzipStream.push(chunk2);\n\n...\n\n// You should mark the last chunk by using true in the second argument\n// In addition to being necessary for the stream to work properly, this\n// will also set the isLast parameter in the handler to true.\ngzipStream.push(lastChunk, true);\n\nconsole.log(outStr); // The compressed binary string is now available\n\n// The options parameter for compression streams is optional; you can\n// provide one parameter (the handler) or none at all if you set\n// deflateStream.ondata later.\nconst deflateStream = new fflate.Deflate((chunk, final) => {\n  console.log(chunk, final);\n});\n\nconst inflateStream = new fflate.Inflate();\ninflateStream.ondata = (decompressedChunk, final) => {\n  // print out a string of the compressed data\n  console.log(fflate.strFromU8(decompressedChunk));\n};\n\n// Decompress streams auto-detect the compression method, as the\n// non-streaming decompress() method does.\nconst dcmpStrm = new fflate.Decompress((chunk, final) => {\n  console.log(\n    'This chunk was encoded in either GZIP, Zlib, or DEFLATE',\n    chunk\n  );\n});\n```\n\nYou can create multi-file ZIP archives easily as well. Note that by default, compression is enabled for all files, which is not useful when ZIPping many PNGs, JPEGs, PDFs, etc. because those formats are already compressed. You should either override the level on a per-file basis or globally to avoid wasting resources.\n```js\n// Note that the asynchronous version (see below) runs in parallel and\n// is *much* (up to 3x) faster for larger archives.\nconst zipped = fflate.zipSync({\n  // Directories can be nested structures, as in an actual filesystem\n  'dir1': {\n    'nested': {\n      // You can use Unicode in filenames\n      '你好.txt': std('Hey there!')\n    },\n    // You can also manually write out a directory path\n    'other/tmp.txt': new Uint8Array([97, 98, 99, 100])\n  },\n  // You can also provide compression options\n  'myImageData.bmp': [aMassiveFile, {\n    level: 9,\n    mem: 12,\n    // ZIP-specific: mtime works here too, defaults to current time\n    mtime: new Date('10/20/2020')\n  }],\n  // PNG is pre-compressed; no need to waste time\n  'superTinyFile.png': [aPNGFile, { level: 0 }]\n}, {\n  // These options are the defaults for all files, but file-specific\n  // options take precedence.\n  level: 1,\n  // Obfuscate mtime by default\n  mtime: 0\n});\n\n// If you write the zipped data to myzip.zip and unzip, the folder\n// structure will be outputted as:\n\n// myzip.zip (original file)\n// dir1\n// |-> nested\n// |   |-> 你好.txt\n// |-> other\n// |   |-> tmp.txt\n// myImageData.bmp\n// superTinyFile.bin\n\n// When decompressing, folders are not nested; all filepaths are fully\n// written out in the keys. For example, the return value may be:\n// { 'nested/directory/a2.txt': Uint8Array(2) [97, 97] })\nconst decompressed = fflate.unzipSync(zipped);\n```\nAs you may have guessed, there is an asynchronous version of every method as well. Unlike most libraries, this will cause the compression or decompression run in a separate thread entirely and automatically by using Web (or Node) Workers. This means that the processing will not block the main thread at all.\n\nNote that there is a significant initial overhead to using workers of about 70ms, so it's best to avoid the asynchronous API unless necessary. However, if you're compressing multiple large files at once, or the synchronous API causes the main thread to hang for too long, the callback APIs are an order of magnitude better.\n```js\nimport { gzip, zlib, AsyncGzip, zip, strFromU8 } from 'fflate';\n\n// Workers will work in almost any browser (even IE11!)\n// However, they fail below Node v12 without the --experimental-worker\n// CLI flag, and will fail entirely on Node below v10.\n\n// All of the async APIs use a node-style callback as so:\nconst terminate = gzip(aMassiveFile, (err, data) => {\n  if (err) {\n    // The compressed data was likely corrupt, so we have to handle\n    // the error.\n    return;\n  }\n  // Use data however you like\n  console.log(data.length);\n});\n\nif (needToCancel) {\n  // The return value of any of the asynchronous APIs is a function that,\n  // when called, will immediately cancel the operation. The callback\n  // will not be called.\n  terminate();\n}\n\n// If you wish to provide options, use the second argument.\n\n// The consume option will render the data inside aMassiveFile unusable,\n// but can dramatically improve performance and reduce memory usage.\nzlib(aMassiveFile, { consume: true, level: 9 }, (err, data) => {\n  // Use the data\n});\n\n// Asynchronous streams are similar to synchronous streams, but the\n// handler has the error that occurred (if any) as the first parameter,\n// and they don't block the main thread.\n\n// Additionally, any buffers that are pushed in will be consumed and\n// rendered unusable; if you need to use a buffer you push in, you\n// should clone it first.\nconst gzs = new AsyncGzip({ level: 9, mem: 12, filename: 'hello.txt' });\nlet wasCallbackCalled = false;\ngzs.ondata = (err, chunk, final) => {\n  // Note the new err parameter\n  if (err) {\n    // Note that after this occurs, the stream becomes corrupt and must\n    // be discarded. You can't continue pushing chunks and expect it to\n    // work.\n    console.error(err);\n    return;\n  }\n  wasCallbackCalled = true;\n}\ngzs.push(chunk);\n\n// Since the stream is asynchronous, the callback will not be called\n// immediately. If such behavior is absolutely necessary (it shouldn't\n// be), use synchronous streams.\nconsole.log(wasCallbackCalled) // false\n\n// To terminate an asynchronous stream's internal worker, call\n// stream.terminate().\ngzs.terminate();\n\n// This is way faster than zipSync because the compression of multiple\n// files runs in parallel. In fact, the fact that it's parallelized\n// makes it faster than most standalone ZIP CLIs. The effect is most\n// significant for multiple large files; less so for many small ones.\nzip({ f1: aMassiveFile, 'f2.txt': anotherMassiveFile }, {\n  // The options object is still optional, you can still do just\n  // zip(archive, callback)\n  level: 6,\n  mtime: 0\n}, (err, data) => {\n  // Save the ZIP file\n});\n\n// unzip is the only async function without support for consume option\n// Also parallelized, so unzip is also often much faster than unzipSync\nunzip(aMassiveZIPFile, (err, unzipped) => {\n  // If the archive has data.xml, log it here\n  console.log(unzipped['data.xml']);\n  // Conversion to string\n  console.log(strFromU8(unzipped['data.xml']))\n})\n```\n\nSee the [documentation](https://github.com/101arrowz/fflate/blob/master/docs/README.md) for more detailed information about the API.\n\n## Bundle size estimates\n\nSince `fflate` uses ES Modules, this table should give you a general idea of `fflate`'s bundle size for the features you need. The maximum bundle size that is possible with `fflate` is about 22kB if you use every single feature, but feature parity with `pako` is only around 10kB (as opposed to 45kB from `pako`). If your bundle size increases dramatically after adding `fflate`, please [create an issue](https://github.com/101arrowz/fflate/issues/new).\n\n| Feature                 | Bundle size (minified)         | Nearest competitor     |\n|-------------------------|--------------------------------|------------------------|\n| Decompression           | 3kB                            | `tiny-inflate`         |\n| Compression             | 5kB                            | `UZIP.js`, 184% larger |\n| Async decompression     | 4kB (1kB + raw decompression)  | N/A                    |\n| Async compression       | 5kB (1kB + raw compression)    | N/A                    |\n| ZIP decompression       | 5kB (2kB + raw decompression)  | `UZIP.js`, 184% larger |\n| ZIP compression         | 7kB (2kB + raw compression)    | `UZIP.js`, 103% larger |\n| GZIP/Zlib decompression | 4kB (1kB + raw decompression)  | `pako`, 1040% larger   |\n| GZIP/Zlib compression   | 5kB (1kB + raw compression)    | `pako`, 812% larger    |\n| Streaming decompression | 4kB (1kB + raw decompression)  | `pako`, 1040% larger   |\n| Streaming compression   | 5kB (1kB + raw compression)    | `pako`, 812% larger    |\n\n## What makes `fflate` so fast?\nMany JavaScript compression/decompression libraries exist. However, the most popular one, [`pako`](https://npmjs.com/package/pako), is merely a clone of Zlib rewritten nearly line-for-line in JavaScript. Although it is by no means poorly made, `pako` doesn't recognize the many differences between JavaScript and C, and therefore is suboptimal for performance. Moreover, even when minified, the library is 45 kB; it may not seem like much, but for anyone concerned with optimizing bundle size (especially library authors), it's more weight than necessary.\n\nNote that there exist some small libraries like [`tiny-inflate`](https://npmjs.com/package/tiny-inflate) for solely decompression, and with a minified size of 3 kB, it can be appealing; however, its performance is lackluster, typically 40% worse than `pako` in my tests.\n\n[`UZIP.js`](https://github.com/photopea/UZIP.js) is both faster (by up to 40%) and smaller (14 kB minified) than `pako`, and it contains a variety of innovations that make it excellent for both performance and compression ratio. However, the developer made a variety of tiny mistakes and inefficient design choices that make it imperfect. Moreover, it does not support GZIP or Zlib data directly; one must remove the headers manually to use `UZIP.js`.\n\nSo what makes `fflate` different? It takes the brilliant innovations of `UZIP.js` and optimizes them while adding direct support for GZIP and Zlib data. And unlike all of the above libraries, it uses ES Modules to allow for partial builds through tree shaking, meaning that it can rival even `tiny-inflate` in size while maintaining excellent performance. The end result is a library that, in total, weighs 8kB minified for the core build (3kB for decompression only and 5kB for compression only), is about 15% faster than `UZIP.js` or up to 60% faster than `pako`, and achieves the same or better compression ratio than the rest.\n\nIf you're willing to have 160 kB of extra weight and [much less browser support](https://caniuse.com/wasm), you could theoretically achieve more performance than `fflate` with a WASM build of Zlib like [`wasm-flate`](https://www.npmjs.com/package/wasm-flate). However, per some tests I conducted, the WASM interpreters of major browsers are not fast enough as of December 2020 for `wasm-flate` to be useful: `fflate` is around 2x faster.\n\nBefore you decide that `fflate` is the end-all compression library, you should note that JavaScript simply cannot rival the performance of a native program. If you're only using Node.js, use the [native Zlib bindings](https://nodejs.org/api/zlib.html) that offer the best performance. Though note that even against Zlib, `fflate` is only around 30% slower in decompression and 10% slower in compression, and can still achieve better compression ratios!\n\n## Browser support\n`fflate` makes heavy use of typed arrays (`Uint8Array`, `Uint16Array`, etc.). Typed arrays can be polyfilled at the cost of performance, but the most recent browser that doesn't support them [is from 2011](https://caniuse.com/typedarrays), so I wouldn't bother.\n\nThe asynchronous APIs also use `Worker`, which is not supported in a few browsers (however, the vast majority of browsers that support typed arrays support `Worker`).\n\nOther than that, `fflate` is completely ES3, meaning you probably won't even need a bundler to use it.\n\n## Testing\nYou can validate the performance of `fflate` with `npm`/`yarn`/`pnpm` `test`. It validates that the module is working as expected, ensures the outputs are no more than 5% larger than competitors at max compression, and outputs performance metrics to `test/results`.\n\nNote that the time it takes for the CLI to show the completion of each test is not representative of the time each package took, so please check the JSON output if you want accurate measurements.\n\n## License\n\nThis software is [MIT Licensed](./LICENSE), with special exemptions for projects\nand organizations as noted below:\n\n- [SheetJS](https://github.com/SheetJS/) is exempt from MIT licensing and may\n  license any source code from this software under the BSD Zero Clause License\n",
    "licenseText": "MIT License\n\nCopyright (c) 2020 Arjun Barrett\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/fflate/-/fflate-0.4.8.tgz#f90b82aefbd8ac174213abb338bd7ef848f0f5ae",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/fflate/-/fflate-0.4.8.tgz",
    "hash": "f90b82aefbd8ac174213abb338bd7ef848f0f5ae",
    "integrity": "sha512-FJqqoDBR00Mdj9ppamLa/Y7vxm+PRmNWA67N846RvsoYVMKB4q3y/de5PA7gUmRMYK/8CMz2GDZQmCRN1wBcWA==",
    "registry": "npm",
    "packageName": "fflate",
    "cacheIntegrity": "sha512-FJqqoDBR00Mdj9ppamLa/Y7vxm+PRmNWA67N846RvsoYVMKB4q3y/de5PA7gUmRMYK/8CMz2GDZQmCRN1wBcWA== sha1-+QuCrvvYrBdCE6uzOL1++Ejw9a4="
  },
  "registry": "npm",
  "hash": "f90b82aefbd8ac174213abb338bd7ef848f0f5ae"
}