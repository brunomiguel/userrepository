{
  "manifest": {
    "name": "@discoveryjs/json-ext",
    "version": "0.5.7",
    "description": "A set of utilities that extend the use of JSON",
    "keywords": [
      "json",
      "utils",
      "stream",
      "async",
      "promise",
      "stringify",
      "info"
    ],
    "author": {
      "name": "Roman Dvornov",
      "email": "rdvornov@gmail.com",
      "url": "https://github.com/lahmatiy"
    },
    "license": "MIT",
    "repository": {
      "type": "git",
      "url": "https://github.com/discoveryjs/json-ext.git"
    },
    "main": "./src/index",
    "browser": {
      "./src/stringify-stream.js": "./src/stringify-stream-browser.js",
      "./src/text-decoder.js": "./src/text-decoder-browser.js",
      "./src/version.js": "./dist/version.js"
    },
    "types": "./index.d.ts",
    "scripts": {
      "test": "mocha --reporter progress",
      "lint": "eslint src test",
      "lint-and-test": "npm run lint && npm test",
      "build": "rollup --config",
      "test:all": "npm run test:src && npm run test:dist",
      "test:src": "npm test",
      "test:dist": "cross-env MODE=dist npm test && cross-env MODE=dist-min npm test",
      "build-and-test": "npm run build && npm run test:dist",
      "coverage": "c8 --reporter=lcovonly npm test",
      "prepublishOnly": "npm run lint && npm test && npm run build-and-test"
    },
    "devDependencies": {
      "@rollup/plugin-commonjs": "^15.1.0",
      "@rollup/plugin-json": "^4.1.0",
      "@rollup/plugin-node-resolve": "^9.0.0",
      "c8": "^7.10.0",
      "chalk": "^4.1.0",
      "cross-env": "^7.0.3",
      "eslint": "^8.10.0",
      "mocha": "^8.4.0",
      "rollup": "^2.28.2",
      "rollup-plugin-terser": "^7.0.2"
    },
    "engines": {
      "node": ">=10.0.0"
    },
    "files": [
      "dist",
      "src",
      "index.d.ts"
    ],
    "_registry": "npm",
    "_loc": "/home/brunomiguel/userrepository/pkgbuild/cerebro/src/yarn-cache/v6/npm-@discoveryjs-json-ext-0.5.7-1d572bfbbe14b7704e0ba0f39b74815b84870d70-integrity/node_modules/@discoveryjs/json-ext/package.json",
    "readmeFilename": "README.md",
    "readme": "# json-ext\n\n[![NPM version](https://img.shields.io/npm/v/@discoveryjs/json-ext.svg)](https://www.npmjs.com/package/@discoveryjs/json-ext)\n[![Build Status](https://github.com/discoveryjs/json-ext/actions/workflows/ci.yml/badge.svg)](https://github.com/discoveryjs/json-ext/actions/workflows/ci.yml)\n[![Coverage Status](https://coveralls.io/repos/github/discoveryjs/json-ext/badge.svg?branch=master)](https://coveralls.io/github/discoveryjs/json-ext?)\n[![NPM Downloads](https://img.shields.io/npm/dm/@discoveryjs/json-ext.svg)](https://www.npmjs.com/package/@discoveryjs/json-ext)\n\nA set of utilities that extend the use of JSON. Designed to be fast and memory efficient\n\nFeatures:\n\n- [x] `parseChunked()` – Parse JSON that comes by chunks (e.g. FS readable stream or fetch response stream)\n- [x] `stringifyStream()` – Stringify stream (Node.js)\n- [x] `stringifyInfo()` – Get estimated size and other facts of JSON.stringify() without converting a value to string\n- [ ] **TBD** Support for circular references\n- [ ] **TBD** Binary representation [branch](https://github.com/discoveryjs/json-ext/tree/binary)\n- [ ] **TBD** WHATWG [Streams](https://streams.spec.whatwg.org/) support\n\n## Install\n\n```bash\nnpm install @discoveryjs/json-ext\n```\n\n## API\n\n- [parseChunked(chunkEmitter)](#parsechunkedchunkemitter)\n- [stringifyStream(value[, replacer[, space]])](#stringifystreamvalue-replacer-space)\n- [stringifyInfo(value[, replacer[, space[, options]]])](#stringifyinfovalue-replacer-space-options)\n    - [Options](#options)\n        - [async](#async)\n        - [continueOnCircular](#continueoncircular)\n- [version](#version)\n\n### parseChunked(chunkEmitter)\n\nWorks the same as [`JSON.parse()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse) but takes `chunkEmitter` instead of string and returns [Promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise).\n\n> NOTE: `reviver` parameter is not supported yet, but will be added in next releases.\n> NOTE: WHATWG streams aren't supported yet\n\nWhen to use:\n- It's required to avoid freezing the main thread during big JSON parsing, since this process can be distributed in time\n- Huge JSON needs to be parsed (e.g. >500MB on Node.js)\n- Needed to reduce memory pressure. `JSON.parse()` needs to receive the entire JSON before parsing it. With `parseChunked()` you may parse JSON as first bytes of it comes. This approach helps to avoid storing a huge string in the memory at a single time point and following GC.\n\n[Benchmark](https://github.com/discoveryjs/json-ext/tree/master/benchmarks#parse-chunked)\n\nUsage:\n\n```js\nconst { parseChunked } = require('@discoveryjs/json-ext');\n\n// as a regular Promise\nparseChunked(chunkEmitter)\n    .then(data => {\n        /* data is parsed JSON */\n    });\n\n// using await (keep in mind that not every runtime has a support for top level await)\nconst data = await parseChunked(chunkEmitter);\n```\n\nParameter `chunkEmitter` can be:\n- [`ReadableStream`](https://nodejs.org/dist/latest-v14.x/docs/api/stream.html#stream_readable_streams) (Node.js only)\n```js\nconst fs = require('fs');\nconst { parseChunked } = require('@discoveryjs/json-ext');\n\nparseChunked(fs.createReadStream('path/to/file.json'))\n```\n- Generator, async generator or function that returns iterable (chunks). Chunk might be a `string`, `Uint8Array` or `Buffer` (Node.js only):\n```js\nconst { parseChunked } = require('@discoveryjs/json-ext');\nconst encoder = new TextEncoder();\n\n// generator\nparseChunked(function*() {\n    yield '{ \"hello\":';\n    yield Buffer.from(' \"wor');    // Node.js only\n    yield encoder.encode('ld\" }'); // returns Uint8Array(5) [ 108, 100, 34, 32, 125 ]\n});\n\n// async generator\nparseChunked(async function*() {\n    for await (const chunk of someAsyncSource) {\n        yield chunk;\n    }\n});\n\n// function that returns iterable\nparseChunked(() => ['{ \"hello\":', ' \"world\"}'])\n```\n\nUsing with [fetch()](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API):\n\n```js\nasync function loadData(url) {\n    const response = await fetch(url);\n    const reader = response.body.getReader();\n\n    return parseChunked(async function*() {\n        while (true) {\n            const { done, value } = await reader.read();\n\n            if (done) {\n                break;\n            }\n\n            yield value;\n        }\n    });\n}\n\nloadData('https://example.com/data.json')\n    .then(data => {\n        /* data is parsed JSON */\n    })\n```\n\n### stringifyStream(value[, replacer[, space]])\n\nWorks the same as [`JSON.stringify()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify), but returns an instance of [`ReadableStream`](https://nodejs.org/dist/latest-v14.x/docs/api/stream.html#stream_readable_streams) instead of string.\n\n> NOTE: WHATWG Streams aren't supported yet, so function available for Node.js only for now\n\nDeparts from JSON.stringify():\n- Outputs `null` when `JSON.stringify()` returns `undefined` (since streams may not emit `undefined`)\n- A promise is resolving and the resulting value is stringifying as a regular one\n- A stream in non-object mode is piping to output as is\n- A stream in object mode is piping to output as an array of objects\n\nWhen to use:\n- Huge JSON needs to be generated (e.g. >500MB on Node.js)\n- Needed to reduce memory pressure. `JSON.stringify()` needs to generate the entire JSON before send or write it to somewhere. With `stringifyStream()` you may send a result to somewhere as first bytes of the result appears. This approach helps to avoid storing a huge string in the memory at a single time point.\n- The object being serialized contains Promises or Streams (see Usage for examples)\n\n[Benchmark](https://github.com/discoveryjs/json-ext/tree/master/benchmarks#stream-stringifying)\n\nUsage:\n\n```js\nconst { stringifyStream } = require('@discoveryjs/json-ext');\n\n// handle events\nstringifyStream(data)\n    .on('data', chunk => console.log(chunk))\n    .on('error', error => consold.error(error))\n    .on('finish', () => console.log('DONE!'));\n\n// pipe into a stream\nstringifyStream(data)\n    .pipe(writableStream);\n```\n\nUsing Promise or ReadableStream in serializing object:\n\n```js\nconst fs = require('fs');\nconst { stringifyStream } = require('@discoveryjs/json-ext');\n\n// output will be\n// {\"name\":\"example\",\"willSerializeResolvedValue\":42,\"fromFile\":[1, 2, 3],\"at\":{\"any\":{\"level\":\"promise!\"}}}\nstringifyStream({\n    name: 'example',\n    willSerializeResolvedValue: Promise.resolve(42),\n    fromFile: fs.createReadStream('path/to/file.json'), // support file content is \"[1, 2, 3]\", it'll be inserted as it\n    at: {\n        any: {\n            level: new Promise(resolve => setTimeout(() => resolve('promise!'), 100))\n        }\n    }\n})\n\n// in case several async requests are used in object, it's prefered\n// to put fastest requests first, because in this case\nstringifyStream({\n    foo: fetch('http://example.com/request_takes_2s').then(req => req.json()),\n    bar: fetch('http://example.com/request_takes_5s').then(req => req.json())\n});\n```\n\nUsing with [`WritableStream`](https://nodejs.org/dist/latest-v14.x/docs/api/stream.html#stream_writable_streams) (Node.js only):\n\n```js\nconst fs = require('fs');\nconst { stringifyStream } = require('@discoveryjs/json-ext');\n\n// pipe into a console\nstringifyStream(data)\n    .pipe(process.stdout);\n\n// pipe into a file\nstringifyStream(data)\n    .pipe(fs.createWriteStream('path/to/file.json'));\n\n// wrapping into a Promise\nnew Promise((resolve, reject) => {\n    stringifyStream(data)\n        .on('error', reject)\n        .pipe(stream)\n        .on('error', reject)\n        .on('finish', resolve);\n});\n```\n\n### stringifyInfo(value[, replacer[, space[, options]]])\n\n`value`, `replacer` and `space` arguments are the same as for `JSON.stringify()`.\n\nResult is an object:\n\n```js\n{\n    minLength: Number,  // minimal bytes when values is stringified\n    circular: [...],    // list of circular references\n    duplicate: [...],   // list of objects that occur more than once\n    async: [...]        // list of async values, i.e. promises and streams\n}\n```\n\nExample:\n\n```js\nconst { stringifyInfo } = require('@discoveryjs/json-ext');\n\nconsole.log(\n    stringifyInfo({ test: true }).minLength\n);\n// > 13\n// that equals '{\"test\":true}'.length\n```\n\n#### Options\n\n##### async\n\nType: `Boolean`  \nDefault: `false`\n\nCollect async values (promises and streams) or not.\n\n##### continueOnCircular\n\nType: `Boolean`  \nDefault: `false`\n\nStop collecting info for a value or not whenever circular reference is found. Setting option to `true` allows to find all circular references.\n\n### version\n\nThe version of library, e.g. `\"0.3.1\"`.\n\n## License\n\nMIT\n",
    "licenseText": "MIT License\n\nCopyright (c) 2020 Roman Dvornov <rdvornov@gmail.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/@discoveryjs/json-ext/-/json-ext-0.5.7.tgz#1d572bfbbe14b7704e0ba0f39b74815b84870d70",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/@discoveryjs/json-ext/-/json-ext-0.5.7.tgz",
    "hash": "1d572bfbbe14b7704e0ba0f39b74815b84870d70",
    "integrity": "sha512-dBVuXR082gk3jsFp7Rd/JI4kytwGHecnCoTtXFb7DB6CNHp4rg5k1bhg0nWdLGLnOV71lmDzGQaLMy8iPLY0pw==",
    "registry": "npm",
    "packageName": "@discoveryjs/json-ext",
    "cacheIntegrity": "sha512-dBVuXR082gk3jsFp7Rd/JI4kytwGHecnCoTtXFb7DB6CNHp4rg5k1bhg0nWdLGLnOV71lmDzGQaLMy8iPLY0pw== sha1-HVcr+74Ut3BOC6Dzm3SBW4SHDXA="
  },
  "registry": "npm",
  "hash": "1d572bfbbe14b7704e0ba0f39b74815b84870d70"
}